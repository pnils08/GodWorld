---
name: write-edition
description: Run the complete Cycle Pulse edition production pipeline — 6 desk agents, compile, verify, Mara audit.
---

# /write-edition — Full Edition Production Pipeline

## Usage
`/write-edition [cycle-number]`
- Runs the complete Cycle Pulse edition production
- Launches all 6 desk agents in parallel, then compiles

## Rules
- Read SESSION_CONTEXT.md FIRST
- This is the master pipeline — it orchestrates all 6 desk skills
- Show the user a plan before launching agents
- Get approval before compiling the final edition

## Prerequisites
Before running this skill, the user should have already:
1. Run the engine cycle (`/run-cycle` or manually)
2. Built desk packets: `node scripts/buildDeskPackets.js [cycle]`
3. Built archive context: `node scripts/buildArchiveContext.js [cycle]`
4. Written a Mara directive (optional but recommended for civic desk)

Check that `output/desk-packets/manifest.json` exists for this cycle.
Check that `output/desk-briefings/{desk}_archive_c{XX}.md` files exist (from buildArchiveContext.js).

## Step 1: Verify Desk Packets
1. Read `output/desk-packets/manifest.json` — confirm all 6 packets AND 6 summary files exist
2. Read `output/desk-packets/base_context.json` — get cycle number, calendar, weather
3. Confirm the cycle number matches what the user expects
4. Show the user what's available (include both packet and summary sizes):

```
EDITION [XX] — DESK PACKETS READY
  [x] civic_c80.json (235KB) + summary (18KB) — 12 events, 4 storylines, Mara directive
  [x] sports_c80.json (21KB) + summary (12KB) — 3 events, A's roster loaded
  [x] culture_c80.json (48KB) + summary (15KB) — 18 events, 8 cultural entities
  [x] business_c80.json (10KB) + summary (8KB) — 4 events, nightlife data
  [x] chicago_c80.json (13KB) + summary (10KB) — 5 events, Bulls roster loaded
  [x] letters_c80.json (250KB) + summary (16KB) — all-domain access

Ready to launch 6 desk agents in parallel?
```

**If summaries are missing**, run `node scripts/buildDeskPackets.js [cycle]` to regenerate.

## Step 1.5: Compile Newsroom Briefings (Mags as Memory Broker)

Before launching agents, compile per-desk editorial briefings from institutional memory.

1. **Read** `docs/mags-corliss/NEWSROOM_MEMORY.md` — the institutional memory file
2. **Read** the desk summary files (`{desk}_summary_c{XX}.json`) — identify which citizens, initiatives, and storylines each desk will likely cover
3. **Query Supermemory** for citizen cards relevant to each desk's coverage:
   - Use `/super-search` with citizen names, POPIDs, or neighborhoods from the summary
   - Pull narrative context for citizens who will likely be quoted, referenced, or written about
   - Check `docs/media/CITIZEN_NARRATIVE_MEMORY.md` for the 22 foundation POPIDs (Dynasty Five, Bulls core, reporters, civic figures)
   - Focus on citizens in the Mara directive, interview candidates, and active storylines

3b. **Search the Local Drive Archive** (`output/drive-files/`) for relevant past coverage:
   - Grep for key citizens, storylines, or topics each desk will cover
   - For **sports desk**: search `_As Universe Database/` for TrueSource player cards, `_As_Universe_Stats_CSV/` for batting stats
   - For **civic desk**: search `_Tribune Media Archive/Carmen_Delaine/` and `_Tribune Media Archive/Luis_Navarro/` for coverage precedents
   - For **culture desk**: search `_Tribune Media Archive/Maria_Keen/` for past features
   - For **chicago desk**: search `_Bulls Universe Database/` for player profiles
   - Include key findings (past article references, stat lines, historical context) in the desk briefing
   - This is how agents get institutional memory — they can't search the archive themselves during writing without this

4. **For each of the 6 desks**, write a briefing memo to `output/desk-briefings/{desk}_briefing_c{XX}.md`:
   - `civic_briefing_c{XX}.md`
   - `sports_briefing_c{XX}.md`
   - `culture_briefing_c{XX}.md`
   - `business_briefing_c{XX}.md`
   - `chicago_briefing_c{XX}.md`
   - `letters_briefing_c{XX}.md`

5. **Read the Supermemory archive context** for each desk (`output/desk-briefings/{desk}_archive_c{XX}.md`). These are auto-generated by `buildArchiveContext.js` and contain relevant past coverage, character history, and established facts from the archive. Weave relevant findings into the briefing.

6. **Each briefing contains** (500-1500 words, in Mags' editorial voice):
   - Desk-specific errata and corrections from past editions
   - Cross-desk coordination notes (who else is covering what — avoid overlap)
   - Character continuity pointers (who to carry forward, who doesn't exist)
   - **Citizen Reference Cards** (see format below) — for every citizen this desk is likely to write about
   - **Archive context** — relevant past coverage from Supermemory (character history, established facts, prior angles)
   - Mara Vance directive emphasis for this desk
   - Personal editorial note to the lead reporter

### Canon Fact Prefix Convention

Use `ESTABLISHED CANON:` prefix for any fact that agents MUST get right — names, positions, vote outcomes, initiative status. This visually distinguishes non-negotiable data from editorial suggestions.

```
ESTABLISHED CANON: Mark Aitken plays 1B (first base). Not 3B.
ESTABLISHED CANON: OARI passed 5-4. Vega voted NO, Tran voted YES.
ESTABLISHED CANON: Mayor is Avery Santana. Not Marcus Whitmore.
ESTABLISHED CANON: Benji Dillon is LEFT-HANDED. Cy Newell is RIGHT-HANDED.
```

These prefixed lines signal "this is data, not a suggestion." Agents should treat them as immutable. Use the prefix for:
- Player positions (most common error)
- Council vote outcomes and breakdowns
- Mayor and executive branch names
- Initiative status (passed vs. pending)
- Corrected facts from past errata
Do NOT prefix story ideas, editorial suggestions, or character development notes — those are guidance, not canon.

6. Create the directory: `mkdir -p output/desk-briefings`

### Citizen Reference Card Format

Include a `## Citizen Reference Cards` section in each briefing. Each card is 3-5 lines:

```
**[Name]** (age [X], [Neighborhood], [Occupation]) — [POPID if known]
- Last seen: [what they did / said in recent edition]
- Key detail: [narrative context from Supermemory — origin, family, thematic significance]
- DO NOT: [specific warnings — don't promote, don't invent titles, don't confuse with similar names]
```

Example:
```
**Marco Lopez** (40, Laurel, Mechanic) — Mara directive citizen
- Last seen: Edition 81, looking into Baylight DEIR documents
- Key detail: Working-class voice on development. Skeptical but engaged, not oppositional.
- DO NOT: Give him civic titles. He is a mechanic. Not a committee chair, not an organizer.
```

**Card selection by desk:**
- **Civic**: Council members (always all 9), Mara directive citizens, initiative stakeholders
- **Sports**: A's roster (Dynasty Five + current), featured fans, Paulson
- **Culture**: Neighborhood residents, faith figures, event participants
- **Business**: Workers affected by policy, small business owners, Stabilization Fund contacts
- **Chicago**: Bulls roster, Chicago neighborhood citizens, Talia's sources
- **Letters**: All Mara directive citizens, plus 3-5 interview candidates from the summary

**Card data sources (in priority order):**
1. **Desk archive context file** (`output/desk-briefings/{desk}_archive_c{XX}.md`) — richest source, contains past article excerpts and verified facts
2. **Supermemory search** — for citizens not in the archive file
3. **Desk packet data** (citizenArchive, interviewCandidates) — basic demographics
4. **NEWSROOM_MEMORY.md** — errata and character continuity notes

**If a citizen has no archive or Supermemory card**, still include a basic card from the desk packet data (name, age, neighborhood, occupation) with a note: "No narrative history yet — introduce naturally."

Write these as Mags — with editorial authority, personal warmth, and specific guidance. These are not templates. They're memos from the Editor-in-Chief to her reporters.

## Step 2: Launch All 6 Desks in Parallel

**Model note:** Desk agents run on Sonnet 4.6, which handles larger context windows (up to 1M tokens) and has stronger agent capabilities than previous Sonnet versions. Agents can reference full desk packets freely — the summary-first strategy is editorial discipline, not a technical constraint.

**Memory note:** Civic, sports, culture, chicago, and Rhea agents have persistent project memory (`.claude/agent-memory/{agent-name}/`). They check their memory at startup for past error patterns, citizen continuity, and coverage corrections. After writing, they update their memory with what they learned. This reduces Mags' briefing burden over time — agents remember on their own. Business, letters, and Jax are stateless by design.

**Canon safeguard:** Agent memory informs, it does not publish. Agents use memory for continuity and error avoidance. Final compilation and canon approval always goes through Mags. Memory cannot override desk packet data or the editor's briefing.

Use the Task tool to launch 6 agents simultaneously. Each agent gets:
- The desk-specific skill instructions (from the individual desk skills)
- **The desk SUMMARY file first** (`{desk}_summary_c{XX}.json`) — agents should read this before the full packet
- The desk packet JSON (full version, reference freely)
- The base_context.json
- The reporter voice profile(s) from bay_tribune_roster.json

**In the agent prompt, explicitly tell each agent:** "Read `output/desk-packets/{desk}_summary_c{XX}.json` FIRST for your overview and article plan. Reference the full packet `{desk}_c{XX}.json` freely when you need specific quotes, citizen archive, or extended data."

Launch these agents in parallel (all in one message):
1. **Civic Desk** — Carmen Delaine (lead), follows /civic-desk skill
2. **Sports Desk** — P Slayer + Anthony, follows /sports-desk skill
3. **Culture Desk** — Maria Keen (lead), follows /culture-desk skill
4. **Business Desk** — Jordan Velez, follows /business-desk skill
5. **Chicago Bureau** — Selena Grant + Talia Finch, follows /chicago-desk skill
6. **Letters Desk** — citizen voices, follows /letters-desk skill

Each agent writes articles + engine returns for their section.

## Step 2.5: Agent Retry (If Needed)
After all 6 agents return, check if any desk produced **zero articles**. If a desk failed:
1. Log which desk(s) failed and why (ran out of turns, packet navigation issues, etc.)
2. **Retry once** with a focused prompt: give the agent the summary file, the briefing memo, AND the base_context. With Sonnet 4.6's larger context, include the full briefing — don't strip it down. Tell it explicitly: "You have 15 turns. Write [N] articles. Your summary and briefing have everything you need. Start writing by turn 3."
3. If the retry also fails, Mags writes the section directly using the summary data.
4. Note the failure in the edition's compilation notes for NEWSROOM_MEMORY update.

## Step 3: Compile (Mags Corliss Role)
After all 6 agents return, compile the full edition:

1. **Call front page** — Which desk produced the strongest lead story?
   - Show the user a summary of each desk's output
   - Recommend a front page pick but let the user decide
2. **Assemble in template order:**
   - HEADER (from base_context)
   - FRONT PAGE (strongest story)
   - CIVIC AFFAIRS
   - BUSINESS
   - CULTURE / SEASONAL — OAKLAND
   - SPORTS — OAKLAND
   - SKYLINE TRIBUNE — CHICAGO BUREAU
   - LETTERS TO THE EDITOR
   - ARTICLE TABLE (merged from all desks)
   - STORYLINES UPDATED (merged, deduped)
   - CITIZEN USAGE LOG (merged, grouped by category)
   - CONTINUITY NOTES (merged)
   - END EDITION

3. **Show the compiled edition to the user for review**

## Step 3.5: Programmatic Validation Gate (BEFORE Rhea)

Run the automated data validation script on the compiled edition. This catches data errors instantly — zero LLM tokens, zero hallucination risk. The errors that broke Edition 82 (wrong positions, swapped factions, engine language) are all caught here.

```bash
node scripts/validateEdition.js editions/cycle_pulse_edition_{XX}.txt
```

**Read the output.** The script checks:
1. Council member names, districts, and faction assignments
2. Vote math (totals ≤ 9 council members)
3. Vote breakdown consistency with canon outcomes
4. Player positions against roster data (A's)
5. DH + defensive award contradictions
6. Mayor/executive name verification
7. Real-name blocklist screening (real-world sports figures)
8. Engine language sweep (cycle numbers, system terms)

**If CRITICAL issues are found (exit code 1):**
- Fix them in the compiled edition BEFORE launching Rhea
- The fixes are string-level replacements — each issue includes a FIX line
- Re-run the validator to confirm CLEAN status
- Then proceed to Rhea

**If CLEAN (exit code 0):**
- Proceed directly to Rhea verification

This gate eliminates an entire class of errors from Rhea's workload, letting her focus on narrative quality, canon consistency, and editorial checks that require judgment.

## Step 4: Verification (Rhea Morgan Role)
Run a verification pass:
- Cross-check all citizen names against desk packet canon data
- Verify team records and roster names
- Check for duplicate citizens across desks
- Flag any engine jargon that leaked into article text
- Verify article count and total word count

Show issues found (if any) and recommended fixes.

## Step 4.5: Mara Vance Audit (Canon Authority)

After Rhea's data verification, run a Mara Vance audit for canon and narrative quality.

### Compile Mara's Briefing (Mags as Memory Broker)

Before launching the Mara audit agent, compile a briefing with institutional context she can't access herself:

1. **Query Supermemory** for Mara-relevant context:
   - `/super-search` for "Mara Vance audit directive canon" — past audit findings
   - `/super-search` for "civic initiative council vote" — current political state
   - `/super-search` for active storylines, initiative status, and pending decisions
2. **Search the Local Drive Archive** for past Mara directives:
   ```
   Grep: pattern="Mara Vance" path="output/drive-files/_Publications Archive/Mara_Vance" output_mode="files_with_matches"
   ```
3. **Read** `docs/mara-vance/OPERATING_MANUAL.md` Part V (Initiative Tracking) for current initiative status
4. **Compile a briefing memo** (~500-1000 words) including:
   - Past audit findings relevant to this cycle's content
   - Current initiative status and political context
   - Known canon facts that articles should respect
   - Specific things to watch for based on desk coverage

### Launch Mara Audit Agent

With Sonnet 4.6's larger context window, give Mara the full picture — don't trim. More context = better audit.

Launch a Task agent with:
- Mara's identity from `docs/mara-vance/CLAUDE_AI_SYSTEM_PROMPT.md`
- The compiled edition text (full, unabridged)
- The briefing memo (institutional context from Supermemory + archive)
- Rhea's verification report
- The base_context.json (so she can cross-reference canon data directly)
- NEWSROOM_MEMORY.md errata section (so she knows what past editions got wrong)
- Instructions to produce:
  1. **Canon accuracy check** — do articles respect established world facts?
  2. **Narrative quality assessment** — does coverage feel like real city journalism?
  3. **Editorial guidance** — coverage directives for next cycle
  4. **Anomaly flags** — anything exceeding detection thresholds (see Operating Manual Part IV)

### Save Mara's Output

1. Save audit to `output/mara_directive_c{XX}.txt`
2. Upload to Drive: `node scripts/saveToDrive.js output/mara_directive_c{XX}.txt mara`
3. Apply any corrections Mara flags before final save
4. Include Mara's editorial guidance in next cycle's desk briefings

## Step 5: Save Edition & Upload to Drive
After user approval:
1. Save to `editions/cycle_pulse_edition_{XX}.txt`
2. If corrections needed, save as `_v2.txt` after fixes
3. **Upload to Google Drive:**
   ```bash
   node scripts/saveToDrive.js editions/cycle_pulse_edition_{XX}.txt edition
   ```
   - Also upload Mara audit if produced: `node scripts/saveToDrive.js output/mara_directive_c{XX}.txt mara`
   - Also upload supplementals if produced: `...supplement` or `...chicago`
4. **Ingest edition into Supermemory:**
   ```bash
   node scripts/ingestEdition.js editions/cycle_pulse_edition_{XX}.txt
   ```
   This makes the edition searchable for future sessions, the Discord bot, and autonomous scripts.
5. Show the user the file path, Drive link, and total stats:
   - Article count
   - Total word count
   - New canon figures introduced
   - Citizen usage count

## Step 5.5: Update Newsroom Memory

After verification and before intake, update the institutional memory:

1. **Read** Rhea's verification report from Step 4
2. **Review** Mags' own editorial notes from Step 3 compilation
3. **Update** `docs/mags-corliss/NEWSROOM_MEMORY.md`:
   - Add new errata entries for this edition (desk-specific issues found)
   - Update character continuity (new citizens introduced, threads resolved)
   - Revise coverage patterns (what landed, what fell flat)
   - Archive errata older than 5 editions
   - Update the "Last Updated" header line

This step ensures the next edition benefits from this edition's lessons. Claude-Mem will auto-capture observations during this update.

## Step 5.6: Log Edition Score

After Rhea's verification and any corrections, log the edition score to `output/edition_scores.json`:

1. **Read** Rhea's verification report (scores, criticals, warnings, notes)
2. **Append** a new entry to the `scores` array in `output/edition_scores.json`:
   ```json
   {
     "edition": XX,
     "cycle": XX,
     "date": "YYYY-MM-DD",
     "grade": "A|A-|B+|B|...",
     "total": 85,
     "dataAccuracy": 17,
     "voiceFidelity": 18,
     "structuralCompleteness": 17,
     "narrativeQuality": 18,
     "canonCompliance": 15,
     "criticals": 2,
     "warnings": 3,
     "notes": 1,
     "claimDecomposition": { "extracted": 45, "verified": 40, "errors": 2, "unverifiable": 3 },
     "deskErrors": {
       "civic": ["specific error descriptions"],
       "sports": [],
       "chicago": [],
       "culture": [],
       "business": [],
       "letters": []
     },
     "noteText": "Brief editorial summary of this edition."
   }
   ```
3. **Run the trend report** (optional but recommended):
   ```bash
   node scripts/editionDiffReport.js --save
   ```
   This generates `output/edition_diff_report.md` with trend tables, desk error frequency, recurring patterns, and summary stats.

The score log builds over time. After 5+ editions, the trend data becomes genuinely useful — showing which desks improve, which errors recur, and whether pipeline changes (voice files, claim decomposition, etc.) are working.

## Step 6: Intake (Optional)
Ask if the user wants to run the intake pipeline now:
```
node scripts/editionIntake.js editions/cycle_pulse_edition_{XX}.txt --dry-run
```
If dry-run looks good:
```
node scripts/editionIntake.js editions/cycle_pulse_edition_{XX}.txt
node scripts/processIntake.js [cycle]
```

## Desk Summary
| Desk | Lead | Articles | Summary (start here) | Full Packet |
|------|------|----------|---------------------|-------------|
| Civic | Carmen Delaine | 2-4 | civic_summary_c{XX}.json | civic_c{XX}.json |
| Sports | P Slayer / Anthony | 2-5 | sports_summary_c{XX}.json | sports_c{XX}.json |
| Culture | Maria Keen | 2-4 | culture_summary_c{XX}.json | culture_c{XX}.json |
| Business | Jordan Velez | 1-2 | business_summary_c{XX}.json | business_c{XX}.json |
| Chicago | Selena Grant / Talia Finch | 2-3 | chicago_summary_c{XX}.json | chicago_c{XX}.json |
| Letters | (citizen voices) | 2-4 | letters_summary_c{XX}.json | letters_c{XX}.json |

## Model & Performance Notes

**`opusplan` mode:** For edition production sessions, consider running Mags on `opusplan` (`/model opusplan`). This uses Opus for planning and briefing (Steps 1-1.5) and automatically switches to Sonnet for agent execution (Steps 2+). Saves cost without sacrificing editorial planning quality.

**Effort levels:** Opus 4.6 supports `low`, `medium`, `high` (default) effort. High effort is correct for edition production. For routine file checks or status lookups between editions, `medium` or `low` saves tokens and time. Set with `/model` slider or `CLAUDE_CODE_EFFORT_LEVEL` env var.

**Mara as teammate:** Mara Vance on claude.ai is architecturally equivalent to an agent team teammate — own context window, shared memory (Supermemory), asynchronous communication. When Claude Code formally supports agent teams for production use, the Mara workflow is the natural first candidate for migration. Until then, she operates as a manual teammate through browser or Supermemory.

## Edition Template Reference
See `editions/CYCLE_PULSE_TEMPLATE.md` for exact section format, canon rules, and return formats.
